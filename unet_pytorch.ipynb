{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6461325,"sourceType":"datasetVersion","datasetId":3731422},{"sourceId":8471617,"sourceType":"datasetVersion","datasetId":5051543}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:35.282171Z","iopub.execute_input":"2024-05-22T10:46:35.282552Z","iopub.status.idle":"2024-05-22T10:46:35.287218Z","shell.execute_reply.started":"2024-05-22T10:46:35.282523Z","shell.execute_reply":"2024-05-22T10:46:35.286076Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:35.532802Z","iopub.execute_input":"2024-05-22T10:46:35.533202Z","iopub.status.idle":"2024-05-22T10:46:35.540137Z","shell.execute_reply.started":"2024-05-22T10:46:35.533176Z","shell.execute_reply":"2024-05-22T10:46:35.539167Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(EncoderBlock, self).__init__()\n        self.conv_block = ConvBlock(in_channels, out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        p = self.pool(x)\n        return x, p","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:35.764008Z","iopub.execute_input":"2024-05-22T10:46:35.764697Z","iopub.status.idle":"2024-05-22T10:46:35.770477Z","shell.execute_reply.started":"2024-05-22T10:46:35.764664Z","shell.execute_reply":"2024-05-22T10:46:35.769520Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ConvLSTM(nn.Module):\n    def __init__(self, in_channels, hidden_channels, kernel_size, padding):\n        super(ConvLSTM, self).__init__()\n        self.conv = nn.Conv2d(in_channels + hidden_channels, 4 * hidden_channels, kernel_size, padding=padding)\n\n    def forward(self, x, hidden):\n        combined_input = torch.cat([x, hidden[0]], dim=1)\n        gates = self.conv(combined_input)\n        ingate, forgetgate, cellgate, outgate = torch.split(gates, gates.size(1) // 4, dim=1)\n        ingate = torch.sigmoid(ingate)\n        forgetgate = torch.sigmoid(forgetgate)\n        cellgate = torch.tanh(cellgate)\n        outgate = torch.sigmoid(outgate)\n        cell = forgetgate * hidden[1] + ingate * cellgate\n        hidden = outgate * torch.tanh(cell)\n        return hidden, cell","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:35.976048Z","iopub.execute_input":"2024-05-22T10:46:35.976669Z","iopub.status.idle":"2024-05-22T10:46:35.985058Z","shell.execute_reply.started":"2024-05-22T10:46:35.976638Z","shell.execute_reply":"2024-05-22T10:46:35.983975Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DecoderBlock, self).__init__()\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv_lstm = ConvLSTM(in_channels=out_channels, hidden_channels=out_channels, kernel_size=3, padding=1)\n\n    def forward(self, x, skip, hidden=None, cell=None):\n        x = self.up(x)\n        x = torch.cat([x, skip], dim=1)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        if hidden is not None and cell is not None:\n            x, _ = self.conv_lstm(x, (hidden, cell))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:36.167218Z","iopub.execute_input":"2024-05-22T10:46:36.167623Z","iopub.status.idle":"2024-05-22T10:46:36.177962Z","shell.execute_reply.started":"2024-05-22T10:46:36.167588Z","shell.execute_reply":"2024-05-22T10:46:36.176854Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class AttentionBlock(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super(AttentionBlock, self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=2, stride=2, padding=0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        psi = F.interpolate(psi, size=x.size()[2:], mode='bilinear', align_corners=True)\n        return x * psi","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:36.354117Z","iopub.execute_input":"2024-05-22T10:46:36.354922Z","iopub.status.idle":"2024-05-22T10:46:36.363976Z","shell.execute_reply.started":"2024-05-22T10:46:36.354881Z","shell.execute_reply":"2024-05-22T10:46:36.362865Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ASPPBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ASPPBlock, self).__init__()\n        self.conv1x1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv3x3_1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv3x3_2 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv3x3_3 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=18, dilation=18, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.output_conv = nn.Sequential(\n            nn.Conv2d(out_channels * 4, out_channels, kernel_size=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x1 = self.conv1x1(x)\n        x2 = self.conv3x3_1(x)\n        x3 = self.conv3x3_2(x)\n        x4 = self.conv3x3_3(x)\n        x = torch.cat((x1, x2, x3, x4), dim=1)\n        x = self.output_conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:36.562128Z","iopub.execute_input":"2024-05-22T10:46:36.562539Z","iopub.status.idle":"2024-05-22T10:46:36.574068Z","shell.execute_reply.started":"2024-05-22T10:46:36.562489Z","shell.execute_reply":"2024-05-22T10:46:36.573080Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SiameseUNet(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(SiameseUNet, self).__init__()\n        self.encoder1_1 = EncoderBlock(in_channels, 32)  \n        self.encoder1_2 = EncoderBlock(32, 64)          \n        self.encoder1_3 = EncoderBlock(64, 128)        \n        self.encoder1_4 = EncoderBlock(128, 256)        \n\n        self.encoder2_1 = EncoderBlock(in_channels, 32)  \n        self.encoder2_2 = EncoderBlock(32, 64)          \n        self.encoder2_3 = EncoderBlock(64, 128)         \n        self.encoder2_4 = EncoderBlock(128, 256)        \n\n        self.aspp = ASPPBlock(256 * 2, 512)             \n\n        self.attn1 = AttentionBlock(512, 256 * 2, 256)  \n        self.attn2 = AttentionBlock(256, 128 * 2, 128)  \n        self.attn3 = AttentionBlock(128, 64 * 2, 64)    \n        self.attn4 = AttentionBlock(64, 32 * 2, 32)     \n\n        self.decoder1 = DecoderBlock(512 + 512, 256)    \n        self.decoder2 = DecoderBlock(256 + 256, 128)    \n        self.decoder3 = DecoderBlock(128 + 128, 64)     \n        self.decoder4 = DecoderBlock(64 + 64, 32)       \n\n        self.final_conv = nn.Conv2d(32, out_channels, kernel_size=1)  # Assuming output channels remain 1\n\n    def forward(self, x1, x2):\n        # Encoder Path\n        s1_1, p1_1 = self.encoder1_1(x1)\n        s2_1, p2_1 = self.encoder1_2(p1_1)\n        s3_1, p3_1 = self.encoder1_3(p2_1)\n        s4_1, p4_1 = self.encoder1_4(p3_1)\n\n        s1_2, p1_2 = self.encoder2_1(x2)\n        s2_2, p2_2 = self.encoder2_2(p1_2)\n        s3_2, p3_2 = self.encoder2_3(p2_2)\n        s4_2, p4_2 = self.encoder2_4(p3_2)\n\n        # ASPP\n        concatenated = torch.cat((p4_1, p4_2), dim=1)\n        b1 = self.aspp(concatenated)\n\n        # Decoder Path with Attention\n        attn_s4 = self.attn1(b1, torch.cat((s4_1, s4_2), dim=1))\n        d1 = self.decoder1(b1, attn_s4)\n\n        attn_s3 = self.attn2(d1, torch.cat((s3_1, s3_2), dim=1))\n        d2 = self.decoder2(d1, attn_s3)\n\n        attn_s2 = self.attn3(d2, torch.cat((s2_1, s2_2), dim=1))\n        d3 = self.decoder3(d2, attn_s2)\n\n        attn_s1 = self.attn4(d3, torch.cat((s1_1, s1_2), dim=1))\n        d4 = self.decoder4(d3, attn_s1)\n\n        outputs = torch.sigmoid(self.final_conv(d4))\n        return outputs\n\n# Define the model\nmodel = SiameseUNet(in_channels=3, out_channels=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:36.764038Z","iopub.execute_input":"2024-05-22T10:46:36.765012Z","iopub.status.idle":"2024-05-22T10:46:36.991018Z","shell.execute_reply.started":"2024-05-22T10:46:36.764977Z","shell.execute_reply":"2024-05-22T10:46:36.990027Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nclass CustomDataset(Dataset):\n    def __init__(self, time1_dir, time2_dir, label_dir, transform=None):\n        self.time1_dir = time1_dir\n        self.time2_dir = time2_dir\n        self.label_dir = label_dir\n        self.transform = transform\n        self.time1_images = sorted(os.listdir(time1_dir))\n        self.time2_images = sorted(os.listdir(time2_dir))\n        self.label_images = sorted(os.listdir(label_dir))\n    \n    def __len__(self):\n        return len(self.time1_images)\n    \n    def __getitem__(self, idx):\n        time1_path = os.path.join(self.time1_dir, self.time1_images[idx])\n        time2_path = os.path.join(self.time2_dir, self.time2_images[idx])\n        label_path = os.path.join(self.label_dir, self.label_images[idx])\n        \n        time1_image = Image.open(time1_path).convert('RGB')\n        time2_image = Image.open(time2_path).convert('RGB')\n        label_image = Image.open(label_path).convert('L')\n        \n        if self.transform:\n            time1_image = self.transform(time1_image)\n            time2_image = self.transform(time2_image)\n            label_image = self.transform(label_image)\n        \n        return (time1_image, time2_image), label_image\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:37.007277Z","iopub.execute_input":"2024-05-22T10:46:37.007597Z","iopub.status.idle":"2024-05-22T10:46:37.018285Z","shell.execute_reply.started":"2024-05-22T10:46:37.007571Z","shell.execute_reply":"2024-05-22T10:46:37.017290Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader instances\ntrain_dataset = CustomDataset('/kaggle/input/sysu-cd/SYSU-CD/train/train/time1', '/kaggle/input/sysu-cd/SYSU-CD/train/train/time2', '/kaggle/input/sysu-cd/SYSU-CD/train/train/label', transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nval_dataset = CustomDataset('/kaggle/input/sysu-cd/SYSU-CD/val/val/time1', '/kaggle/input/sysu-cd/SYSU-CD/val/val/time2', '/kaggle/input/sysu-cd/SYSU-CD/val/val/label', transform=transform)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n\ntest_dataset = CustomDataset('/kaggle/input/sysu-cd/SYSU-CD/test/test/time1', '/kaggle/input/sysu-cd/SYSU-CD/test/test/time2', '/kaggle/input/sysu-cd/SYSU-CD/test/test/label', transform=transform)\ntest_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:46:38.788093Z","iopub.execute_input":"2024-05-22T10:46:38.788450Z","iopub.status.idle":"2024-05-22T10:47:11.333036Z","shell.execute_reply.started":"2024-05-22T10:46:38.788421Z","shell.execute_reply":"2024-05-22T10:47:11.331499Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sysu-cd/SYSU-CD/val/val/time1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sysu-cd/SYSU-CD/val/val/time2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sysu-cd/SYSU-CD/val/val/label\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m      6\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/sysu-cd/SYSU-CD/test/test/time1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/sysu-cd/SYSU-CD/test/test/time2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/sysu-cd/SYSU-CD/test/test/label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, time1_dir, time2_dir, label_dir, transform)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir \u001b[38;5;241m=\u001b[39m label_dir\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime1_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime1_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime2_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(time2_dir))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(label_dir))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import torch.optim as optim\n# Initialize the  loss function, and optimizer\n\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n\n# Define device (GPU/CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:14.390903Z","iopub.execute_input":"2024-05-22T10:47:14.391250Z","iopub.status.idle":"2024-05-22T10:47:14.442009Z","shell.execute_reply.started":"2024-05-22T10:47:14.391221Z","shell.execute_reply":"2024-05-22T10:47:14.441130Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"SiameseUNet(\n  (encoder1_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (aspp): ASPPBlock(\n    (conv1x1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_2): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_3): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (output_conv): Sequential(\n      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (attn1): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn2): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn3): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn4): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (decoder1): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder2): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder3): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder4): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"def save_checkpoint(state, filename='model_checkpoint.pth.tar'):\n    print('=>saving')\n    torch.save(state, filename)\n\n# Function to load the model checkpoint\ndef load_checkpoint(filename='model_checkpoint.pth.tar', model=None, optimizer=None):\n    if os.path.isfile(filename):\n        print(f\"Loading checkpoint '{filename}'\")\n        checkpoint = torch.load(filename)\n        if model is not None:\n            model.load_state_dict(checkpoint['state_dict'])\n        if optimizer is not None:\n            optimizer.load_state_dict(checkpoint['optimizer'])\n        return checkpoint\n    else:\n        print(f\"No checkpoint found at '{filename}'\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:10.596101Z","iopub.execute_input":"2024-05-22T08:36:10.596368Z","iopub.status.idle":"2024-05-22T08:36:10.602506Z","shell.execute_reply.started":"2024-05-22T08:36:10.596345Z","shell.execute_reply":"2024-05-22T08:36:10.601609Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, model_save_path):\n    best_loss = float('inf')\n    patience_counter = 0\n    start_epoch = 0\n\n    # Load checkpoint if it exists\n    checkpoint = load_checkpoint(model_save_path, model, optimizer)\n    if checkpoint:\n        start_epoch = checkpoint.get('epoch', 0) + 1\n        best_loss = checkpoint.get('best_loss', float('inf'))\n\n    for epoch in range(start_epoch, num_epochs):\n        model.train()\n        train_losses = []\n\n        for (time1_image, time2_image), target in train_loader:\n            time1_image, time2_image, target = time1_image.to(device), time2_image.to(device), target.to(device)\n\n            optimizer.zero_grad()\n            output = model(time1_image, time2_image)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        val_loss = evaluate(model, val_loader, criterion)\n        print(f'Epoch {epoch+1}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {val_loss:.4f}')\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            patience_counter = 0\n            save_checkpoint({\n                'epoch': epoch,\n                'state_dict': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'best_loss': best_loss\n            }, model_save_path)\n        else:\n            patience_counter += 1\n\n        if patience_counter >= patience:\n            print(\"Early stopping\")\n            break\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:10.603613Z","iopub.execute_input":"2024-05-22T08:36:10.603914Z","iopub.status.idle":"2024-05-22T08:36:10.616603Z","shell.execute_reply.started":"2024-05-22T08:36:10.603880Z","shell.execute_reply":"2024-05-22T08:36:10.615784Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate the model\ndef evaluate(model, val_loader, criterion):\n    model.eval()\n    val_losses = []\n    with torch.no_grad():\n        for (time1, time2), target in val_loader:\n            time1, time2, target = time1.to(device), time2.to(device), target.to(device)\n            output = model(time1, time2)\n            loss = criterion(output, target)\n            val_losses.append(loss.item())\n    return np.mean(val_losses)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:10.617735Z","iopub.execute_input":"2024-05-22T08:36:10.618014Z","iopub.status.idle":"2024-05-22T08:36:10.631161Z","shell.execute_reply.started":"2024-05-22T08:36:10.617990Z","shell.execute_reply":"2024-05-22T08:36:10.630347Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Function to count the number of parameters\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters())\n\n# Function to count the number of trainable parameters\ndef count_trainable_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# Print the number of parameters\ntotal_params = count_parameters(model)\ntrainable_params = count_trainable_parameters(model)\nprint(f\"Total parameters: {total_params}\")\nprint(f\"Trainable parameters: {trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:10.632314Z","iopub.execute_input":"2024-05-22T08:36:10.633091Z","iopub.status.idle":"2024-05-22T08:36:10.642912Z","shell.execute_reply.started":"2024-05-22T08:36:10.633064Z","shell.execute_reply":"2024-05-22T08:36:10.642036Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Total parameters: 21804365\nTrainable parameters: 21804365\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model path\nmodel_save_path = '/kaggle/working/siamese_unet_best_model.pth'\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:10.644148Z","iopub.execute_input":"2024-05-22T08:36:10.644845Z","iopub.status.idle":"2024-05-22T08:36:10.656658Z","shell.execute_reply.started":"2024-05-22T08:36:10.644814Z","shell.execute_reply":"2024-05-22T08:36:10.655837Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3, model_save_path=model_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:52.895339Z","iopub.execute_input":"2024-05-22T08:36:52.896030Z","iopub.status.idle":"2024-05-22T09:31:06.306786Z","shell.execute_reply.started":"2024-05-22T08:36:52.895985Z","shell.execute_reply":"2024-05-22T09:31:06.305572Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"No checkpoint found at '/kaggle/working/siamese_unet_best_model.pth'\nEpoch 1, Train Loss: 0.2154, Val Loss: 0.3537\n=>saving\nEpoch 4, Train Loss: 0.1805, Val Loss: 0.3328\n=>saving\nEpoch 5, Train Loss: 0.1709, Val Loss: 0.3383\nEpoch 6, Train Loss: 0.1613, Val Loss: 0.3350\nEpoch 7, Train Loss: 0.1529, Val Loss: 0.3359\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the best model\nload_checkpoint(model_save_path, model, optimizer)\n\n# Evaluate on the validation set\nval_loss = evaluate(model, val_loader, criterion)\nprint(\"Validation Loss:\", val_loss)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:16.914363Z","iopub.status.idle":"2024-05-22T08:36:16.914753Z","shell.execute_reply.started":"2024-05-22T08:36:16.914587Z","shell.execute_reply":"2024-05-22T08:36:16.914602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n\ndef calculate_metrics(y_true, y_pred, threshold=0.5):\n    y_pred = (y_pred > threshold).float()\n    \n    y_true_np = y_true.cpu().numpy().flatten()\n    y_pred_np = y_pred.cpu().numpy().flatten()\n    \n    accuracy = accuracy_score(y_true_np, y_pred_np)\n    precision = precision_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    recall = recall_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    f1 = f1_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    iou = jaccard_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    \n    return accuracy, precision, recall, f1, iou\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:16.915950Z","iopub.status.idle":"2024-05-22T08:36:16.916341Z","shell.execute_reply.started":"2024-05-22T08:36:16.916164Z","shell.execute_reply":"2024-05-22T08:36:16.916179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_metric_model(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0.0\n    all_true = []\n    all_pred = []\n    \n    with torch.no_grad():\n        for (time1, time2), target in test_loader:\n            time1, time2, target = time1.to(device), time2.to(device), target.to(device)\n            output = model(time1, time2)\n            loss = criterion(output, target)\n            test_loss += loss.item()\n\n            all_true.append(target)\n            all_pred.append(output)\n    \n    # Concatenate all batches\n    all_true = torch.cat(all_true, dim=0)\n    all_pred = torch.cat(all_pred, dim=0)\n    \n    # Calculate metrics\n    accuracy, precision, recall, f1, iou = calculate_metrics(all_true, all_pred)\n    \n    return test_loss / len(test_loader), accuracy, precision, recall, f1, iou\n\n# Assuming model, test_loader, criterion, and device are defined as in your code\ntest_loss, accuracy, precision, recall, f1, iou = test_metric_model(model, test_loader, criterion, device)\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\nprint(f'IoU: {iou:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:36:16.917752Z","iopub.status.idle":"2024-05-22T08:36:16.918118Z","shell.execute_reply.started":"2024-05-22T08:36:16.917941Z","shell.execute_reply":"2024-05-22T08:36:16.917956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch.utils.data import DataLoader\n\ndef calculate_iou(predictions, labels):\n    intersection = np.logical_and(predictions, labels).sum()\n    union = np.logical_or(predictions, labels).sum()\n    iou = intersection / union if union != 0 else 0\n    return iou\n\n\nload_checkpoint(model_save_path, model, optimizer=None)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize lists to store evaluation results\naccuracies = []\nprecisions = []\nrecalls = []\nf1_scores = []\nious=[]\n\n# Ensure no gradients are computed during evaluation\nwith torch.no_grad():\n    # Iterate through the test dataloader\n    for (time1_image, time2_image), labels in test_loader:\n        # Convert inputs and labels to PyTorch tensors and move to the appropriate device\n        time1_image = time1_image.to(device)\n        time2_image = time2_image.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(time1_image, time2_image)\n        \n        # Convert outputs to binary predictions\n        predictions = (outputs > 0.5).float()\n        \n        # Ensure the predictions are binary\n        predictions_np = predictions.cpu().detach().numpy().astype(int)\n        labels_np = labels.cpu().detach().numpy().astype(int)\n        \n        # Flatten arrays for sklearn metrics\n        predictions_flat = predictions_np.flatten()\n        labels_flat = labels_np.flatten()\n        \n        # Calculate metrics\n        accuracy = accuracy_score(labels_flat, predictions_flat)\n        precision = precision_score(labels_flat, predictions_flat, zero_division=1)\n        recall = recall_score(labels_flat, predictions_flat, zero_division=1)\n        f1 = f1_score(labels_flat, predictions_flat, zero_division=1)\n        \n        iou = calculate_iou(predictions_np, labels_np)\n        \n        # Append results to lists\n        accuracies.append(accuracy)\n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n        ious.append(iou)\n\n# Calculate average metrics\navg_accuracy = np.mean(accuracies)\navg_precision = np.mean(precisions)\navg_recall = np.mean(recalls)\navg_f1 = np.mean(f1_scores)\navg_iou = np.mean(ious)\n\nprint(\"Average Accuracy:\", avg_accuracy)\nprint(\"Average Precision:\", avg_precision)\nprint(\"Average Recall:\", avg_recall)\nprint(\"Average F1 Score:\", avg_f1)\nprint(\"Average IoU:\", avg_iou)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:00:08.452683Z","iopub.execute_input":"2024-05-22T10:00:08.453360Z","iopub.status.idle":"2024-05-22T10:11:53.170763Z","shell.execute_reply.started":"2024-05-22T10:00:08.453330Z","shell.execute_reply":"2024-05-22T10:11:53.169667Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Loading checkpoint '/kaggle/working/siamese_unet_best_model.pth'\nAverage Accuracy: 0.8778893890380859\nAverage Precision: 0.7460868496412015\nAverage Recall: 0.606769371443158\nAverage F1 Score: 0.6496080962940739\nAverage IoU: 0.4989338817219578\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n# Assuming SiameseUNet and related classes are defined as in your provided code\n# Define the model\nmodel = SiameseUNet(in_channels=3, out_channels=1)\n\n# Load the model checkpoint\nmodel_save_path = '/kaggle/working/siamese_unet_best_model.pth'\nload_checkpoint(model_save_path, model, optimizer=None)\n\n# Set the model to evaluation mode\nmodel.eval()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:32:01.286250Z","iopub.execute_input":"2024-05-22T09:32:01.286627Z","iopub.status.idle":"2024-05-22T09:32:01.764509Z","shell.execute_reply.started":"2024-05-22T09:32:01.286598Z","shell.execute_reply":"2024-05-22T09:32:01.763532Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Loading checkpoint '/kaggle/working/siamese_unet_best_model.pth'\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"SiameseUNet(\n  (encoder1_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (aspp): ASPPBlock(\n    (conv1x1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_2): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_3): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (output_conv): Sequential(\n      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (attn1): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn2): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn3): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn4): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (decoder1): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder2): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder3): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder4): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torchvision.transforms as transforms\n# Define the transformations (resize and convert to tensor)\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:19.232184Z","iopub.execute_input":"2024-05-22T10:47:19.232514Z","iopub.status.idle":"2024-05-22T10:47:19.239067Z","shell.execute_reply.started":"2024-05-22T10:47:19.232487Z","shell.execute_reply":"2024-05-22T10:47:19.238102Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\n\n# Load the images\ndef load_image(image_path, transform):\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image)\n    image = image.unsqueeze(0)  # Add batch dimension\n    return image.to(device)\n\n# Example image paths\ntime1_image_path = '/kaggle/input/sysu-cd/SYSU-CD/test/test/time1/00878.png'\ntime2_image_path = '/kaggle/input/sysu-cd/SYSU-CD/test/test/time2/00878.png'\nlabel_image_path='/kaggle/input/sysu-cd/SYSU-CD/test/test/label/00878.png'\n# Preprocess the images\ntime1_image = load_image(time1_image_path, transform)\ntime2_image = load_image(time2_image_path, transform)\nlabel_image=load_image(label_image_path, transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:20.051025Z","iopub.execute_input":"2024-05-22T10:47:20.051610Z","iopub.status.idle":"2024-05-22T10:47:20.334447Z","shell.execute_reply.started":"2024-05-22T10:47:20.051579Z","shell.execute_reply":"2024-05-22T10:47:20.333619Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Make predictions\nwith torch.no_grad():\n    output = model(time1_image, time2_image)\n\n# Convert the output to a binary mask (if required)\nprediction = (output > 0.5).float()\n\n# To convert the tensor to a numpy array (for further processing or saving the output image)\nprediction_np = prediction.squeeze().cpu().numpy()\n\n# Optionally, save the output prediction as an image\nimport numpy as np\nfrom PIL import Image\n\nprediction_image = Image.fromarray((prediction_np * 255).astype(np.uint8))\nprediction_image.save('/kaggle/working/prediction_image00878.png')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:47:25.148314Z","iopub.execute_input":"2024-05-22T10:47:25.148673Z","iopub.status.idle":"2024-05-22T10:47:25.900624Z","shell.execute_reply.started":"2024-05-22T10:47:25.148645Z","shell.execute_reply":"2024-05-22T10:47:25.899806Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}